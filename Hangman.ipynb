{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Project Description:\n",
    "\n",
    "## CSE 250 A: Artificial Intelligence - Probabilistic Reasoning and Decision Making;  \n",
    "\n",
    "\n",
    "### HW 1 Project:\n",
    "Imagine a game in which you are asked to guess the word w one letter at a time. The rules of this game\n",
    "are as follows: \n",
    "\n",
    "After each letter (A through Z) that you guess, youâ€™ll be told whether the letter appears in\n",
    "the word and also where it appears. Given the evidence that you have at any stage in this game, the critical\n",
    "question is what letter to guess next. Solve this question using Bayesian network.\n",
    "\n",
    "At any point of time, you are given some letters(>=0) of the word, with their positions. You are also given some letters that are not present in the word. The task is to find out the next best guess, given the aforementioned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file to take input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the dictionary: 6535\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('hw1_word_counts_05.txt', sep=\" \", header = None)\n",
    "data.columns = [\"word\", \"count\"]\n",
    "# print data.head(10)\n",
    "number_of_words = data.shape[0]\n",
    "print \"Number of words in the dictionary: %d\" %(number_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort the dataframe and print most-frequent, least-frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 most frequent words are as follows:\n",
      "--------------------\n",
      "  word   count\n",
      " THREE  273077\n",
      " SEVEN  178842\n",
      " EIGHT  165764\n",
      " WOULD  159875\n",
      " ABOUT  157448\n",
      " THEIR  145434\n",
      " WHICH  142146\n",
      " AFTER  110102\n",
      " FIRST  109957\n",
      " FIFTY  106869\n",
      " OTHER  106052\n",
      " FORTY   94951\n",
      " YEARS   88900\n",
      " THERE   86502\n",
      " SIXTY   73086\n",
      "--------------------\n",
      "\n",
      "14 least frequent words are as follows:\n",
      "--------------------\n",
      "  word  count\n",
      " BOSAK      6\n",
      " CAIXA      6\n",
      " MAPCO      6\n",
      " OTTIS      6\n",
      " TROUP      6\n",
      " CCAIR      7\n",
      " CLEFT      7\n",
      " FABRI      7\n",
      " FOAMY      7\n",
      " NIAID      7\n",
      " PAXON      7\n",
      " SERNA      7\n",
      " TOCOR      7\n",
      " YALOM      7\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "data = data.sort_values(\"count\", ascending=False)\n",
    "print \"15 most frequent words are as follows:\"\n",
    "print \"-\"*20\n",
    "print data.head(15).to_string(index = False)\n",
    "print \"-\"*20+\"\\n\"\n",
    "print \"14 least frequent words are as follows:\"\n",
    "print \"-\"*20\n",
    "print data.tail(14).sort_values([\"count\",\"word\"]).to_string(index = False)\n",
    "print \"-\"*20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate prior probability of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7664857\n",
      "       word   count  prob_of_word\n",
      "5821  THREE  273077      0.035627\n",
      "5102  SEVEN  178842      0.023333\n",
      "1684  EIGHT  165764      0.021626\n",
      "6403  WOULD  159875      0.020858\n",
      "18    ABOUT  157448      0.020542\n"
     ]
    }
   ],
   "source": [
    "prob_of_word = []\n",
    "total_count = data[\"count\"].sum()\n",
    "print total_count\n",
    "for row in data[\"count\"]:\n",
    "    prob_of_word.append(row/total_count)\n",
    "data['prob_of_word'] = prob_of_word\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make data structures to store constraints\n",
    "### 1. positive_constraints: To store existing letters and their positions\n",
    "### 2. negative_constraints: To store exception list (letters that did not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Position Value\n",
      "0         1    {}\n",
      "1         2    {}\n",
      "2         3    {}\n",
      "3         4    {}\n",
      "4         5    {}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "positions = range(1,6)\n",
    "chars = \"_\"*5\n",
    "#Map of current state that indicates which character occupies which position. Empty space is '_'\n",
    "positive_constraints = pd.DataFrame({'Position': positions, 'Value':list(chars)})\n",
    "# print positive_constraints\n",
    "\n",
    "sets = [set() for i in range(1,6)]\n",
    "#Map of current state that indicates which character either did not exist or already used in the word\n",
    "negative_constraints = pd.DataFrame({'Position': positions, 'Value':sets})\n",
    "print negative_constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate values for questions in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### 1. correctly guessed = \"D -- -- -- I\"  |   incorrectly guessed = { }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Position Value\n",
      "0         1     D\n",
      "1         2     _\n",
      "2         3     _\n",
      "3         4     I\n",
      "4         5     _\n",
      "   Position   Value\n",
      "0         1     {I}\n",
      "1         2  {I, D}\n",
      "2         3  {I, D}\n",
      "3         4     {D}\n",
      "4         5  {I, D}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sets complement of positive constraints in negative constraints\n",
    "def set_negative_constraints(position, value):\n",
    "    for index, row in negative_constraints.iterrows():\n",
    "        if row['Position'] != position:\n",
    "            temp = negative_constraints.get_value(row['Position']-1, 'Value')\n",
    "            temp.add(value)\n",
    "            negative_constraints.set_value(row['Position']-1, 'Value', temp)\n",
    "    \n",
    "# Setting positive constraints\n",
    "exception_set = set({'D','I'})\n",
    "positive_constraints.set_value(0, 'Value', \"D\")\n",
    "positive_constraints.set_value(3, 'Value', \"I\")\n",
    "exception_set = set({'D','I'})\n",
    "print positive_constraints\n",
    "\n",
    "for index, row in positive_constraints.iterrows():\n",
    "    if row['Value'] != '_' and row['Value']!=' ':\n",
    "        set_negative_constraints(row['Position'], row['Value'])\n",
    "\n",
    "# Setting negative constraints\n",
    "neg_list = ['']\n",
    "if not neg_list:\n",
    "    exception_set.update(neg_list)\n",
    "    for i in neg_list:\n",
    "        print i, type(i)\n",
    "        for index, row in negative_constraints.iterrows():\n",
    "            temp = negative_constraints.get_value(index, 'Value')\n",
    "            temp.add(i)\n",
    "            negative_constraints.set_value(index, 'Value', temp)\n",
    "\n",
    "print negative_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def positive_satisfied(word, pos_constraint):\n",
    "    for index, row in pos_constraint.iterrows():\n",
    "        if row['Value'] != '_':\n",
    "            if word[row['Position']-1] != row['Value']:\n",
    "                return 0\n",
    "    return 1\n",
    "\n",
    "def negative_satisfied(word, neg_constraint):\n",
    "    for index, row in neg_constraint.iterrows():\n",
    "        if len(row['Value'])>0:\n",
    "            if word[row['Position']-1] in row['Value']:\n",
    "                return 0\n",
    "    return 1\n",
    "\n",
    "\n",
    "def prob_evidence_given_word(word, pos_constraint, neg_constraint):\n",
    "    return positive_satisfied(word, pos_constraint) and negative_satisfied(word, neg_constraint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_evidence= {}\n",
    "for index, row in data.iterrows():\n",
    "    word_evidence[row['word']] = prob_evidence_given_word(row['word'], positive_constraints, negative_constraints)\n",
    "\n",
    "# print word_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PSEUDOCODE:\n",
    "# for each alphabet in alphabet_available:\n",
    "    # find argmax(alphabet): p(alphabet|evidence) = sum over each word: p(word|evidence) * p(alphabet|word) .............(1)\n",
    "        # Now, p(alphabet|word) = 1 if word contains alphabet else 0 ..................................(2)\n",
    "        # p(word|evidence) = [p(evidence|word) * p(word)]/[p(evidence)] ...............................(3)\n",
    "            # Now p(evidence|word) = 1 if evidence agrees with word else 0 ............................(4)\n",
    "            # p(evidence) = sum over each word : p(word, evidence) \n",
    "            #             = sum over each word : p(word) * p(evidence|word) ...........................(5)\n",
    "            # Put (4) and (5) in (3)\n",
    "            # Put (2) and (3) in (1)\n",
    "# prob_alphabets_given_evidence =  pd.DataFrame({'Alphabet':alphabet_list, 'Probability':np.zeros(26)})\n",
    "# prob_alphabets_given_evidence = pd.DataFrame({'Alphabet':['E'], 'Probability':[0]})\n",
    "\n",
    "# for index, row in prob_alphabets_given_evidence.iterrows():\n",
    "#     waste_words = []\n",
    "#     total_prob_value = 0\n",
    "#     for data_index, data_row in data.iterrows():\n",
    "#         word = data_row['word']\n",
    "#         print word\n",
    "#         if row['Alphabet'] not in word:\n",
    "#             # return 0 as per step 2\n",
    "#             # update alphabets dataframe\n",
    "#             waste_words.append(word)\n",
    "#             prob_alphabets_given_evidence.set_value(index, 'Probability',0)\n",
    "#             continue\n",
    "            \n",
    "#         # calculating p(word|evidence)\n",
    "#         numerator = prob_evidence_given_word(word, positive_constraints, negative_constraints)*data_row['prob_of_word']\n",
    "#         if numerator == 0:\n",
    "#             # return 0 as per step 4\n",
    "#             # update alphabets dataframe\n",
    "#             waste_words.append(word)\n",
    "#             prob_alphabets_given_evidence.set_value(index, 'Probability',0)\n",
    "#             continue\n",
    "        \n",
    "#         denominator = 0\n",
    "#         final_prob_value = 0\n",
    "#         for data_two_index, data_two_row in data.iterrows():\n",
    "#             if data_two_row['word'] not in waste_words:\n",
    "#                 denominator += prob_evidence_given_word(data_two_row['word'], \n",
    "#                                                     positive_constraints, \n",
    "#                                                     negative_constraints) *data_two_row['prob_of_word']\n",
    "#         final_prob_value = numerator/denominator\n",
    "#         total_prob_value+= final_prob_value\n",
    "#         #update alphabets dataframe\n",
    "#     print \"Probability for: \", row['Alphabet'],\" is :\", total_prob_value\n",
    "#     prob_alphabets_given_evidence.set_value(index, 'Probability',total_prob_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for:  A  is : 0.82068452381\n",
      "Probability for:  B  is : 0.0171130952381\n",
      "Probability for:  C  is : 0\n",
      "Probability for:  E  is : 0.140811011905\n",
      "Probability for:  F  is : 0\n",
      "Probability for:  G  is : 0\n",
      "Probability for:  H  is : 0\n",
      "Probability for:  J  is : 0.00688244047619\n",
      "Probability for:  K  is : 0.00316220238095\n",
      "Probability for:  L  is : 0.0738467261905\n",
      "Probability for:  M  is : 0.0178571428571\n",
      "Probability for:  N  is : 0.186011904762\n",
      "Probability for:  O  is : 0.0453869047619\n",
      "Probability for:  P  is : 0.00688244047619\n",
      "Probability for:  Q  is : 0\n",
      "Probability for:  R  is : 0.180989583333\n",
      "Probability for:  S  is : 0.739583333333\n",
      "Probability for:  T  is : 0.0152529761905\n",
      "Probability for:  U  is : 0.00186011904762\n",
      "Probability for:  V  is : 0.743675595238\n",
      "Probability for:  W  is : 0\n",
      "Probability for:  X  is : 0\n",
      "Probability for:  Y  is : 0\n",
      "Probability for:  Z  is : 0\n"
     ]
    }
   ],
   "source": [
    "# FILTERING WORD WITH EVIDENCE BEFOREHAND\n",
    "# PSEUDOCODE:\n",
    "# for each alphabet in alphabet_available:\n",
    "    # find argmax(alphabet): p(alphabet|evidence) = sum over each word: p(word|evidence) * p(alphabet|word) .............(1)\n",
    "        # Now, p(alphabet|word) = 1 if word contains alphabet else 0 ..................................(2)\n",
    "        # p(word|evidence) = [p(evidence|word) * p(word)]/[p(evidence)] ...............................(3)\n",
    "            # Now p(evidence|word) = 1 if evidence agrees with word else 0 ............................(4)\n",
    "            # p(evidence) = sum over each word : p(word, evidence) \n",
    "            #             = sum over each word : p(word) * p(evidence|word) ...........................(5)\n",
    "            # Put (4) and (5) in (3)\n",
    "            # Put (2) and (3) in (1)\n",
    "prob_alphabets_given_evidence =  pd.DataFrame({'Alphabet':alphabet_list, 'Probability':np.zeros(26)})\n",
    "\n",
    "for index, row in prob_alphabets_given_evidence.iterrows():\n",
    "    if row['Alphabet'] in exception_set: # if they are in one of the constraints, then don't evaluate them\n",
    "        continue\n",
    "    total_prob_value = 0\n",
    "    for data_index, data_row in data.iterrows():\n",
    "        word = data_row['word']\n",
    "        if word_evidence[word]==0: # if word does not agree with the evidence, don't evaluate (saves some time)\n",
    "            continue\n",
    "        if row['Alphabet'] not in word:\n",
    "            # return 0 as per step 2\n",
    "            # update alphabets dataframe\n",
    "            prob_alphabets_given_evidence.set_value(index, 'Probability',0)\n",
    "            continue\n",
    "            \n",
    "        # calculating p(word|evidence)\n",
    "        numerator = prob_evidence_given_word(word, positive_constraints, negative_constraints)*data_row['prob_of_word']\n",
    "        if numerator == 0:\n",
    "            # return 0 as per step 4\n",
    "            # update alphabets dataframe\n",
    "            prob_alphabets_given_evidence.set_value(index, 'Probability',0)\n",
    "            continue\n",
    "        \n",
    "        # if none of the above values are 0, apply Bayes rule\n",
    "        denominator = 0\n",
    "        final_prob_value = 0\n",
    "        for data_two_index, data_two_row in data.iterrows():\n",
    "            denominator += prob_evidence_given_word(data_two_row['word'], \n",
    "                                                    positive_constraints, \n",
    "                                                    negative_constraints) *data_two_row['prob_of_word']\n",
    "        final_prob_value = numerator/denominator\n",
    "        total_prob_value+= final_prob_value\n",
    "        #update alphabets dataframe\n",
    "#     print \"Probability for: \", row['Alphabet'],\" is :\", total_prob_value\n",
    "    prob_alphabets_given_evidence.set_value(index, 'Probability',total_prob_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Alphabet  Probability\n",
      "0        A     0.820685\n"
     ]
    }
   ],
   "source": [
    "result = prob_alphabets_given_evidence.sort_values(\"Probability\", ascending=False)\n",
    "print result[['Alphabet', 'Probability']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
